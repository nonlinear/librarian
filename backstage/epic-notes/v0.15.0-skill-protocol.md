**v0.15.0 - Skill as Protocol**

```mermaid
flowchart TB
    TRIGGER(["Trigger + context"])
    TRIGGER --> METADATA(["Load metadata _1_"])
    METADATA --> CHECK{"Metadata exists?"}
    
    CHECK -->|"No"| ERROR(["*ü§ö No metadata found:<br>Run librarian index* _5_"])
    CHECK -->|"Yes"| INFER{"Infer scope? _2_"}
    
    INFER -->|"confidence<br>lower than 75%"| CLARIFY(["*ü§ö Say it again?* _5_"])
    INFER -->|"confidence<br>higher than 75%"| BUILD(["Build command _3_"])
    
    BUILD --> CHECK_SYSTEM{"System working?"}
    
    CHECK_SYSTEM -->|"No"| BROKEN(["*ü§ö System is broken* _5_"])
    CHECK_SYSTEM -->|"Yes"| EXEC(["Run python script with flags"])
    
    EXEC --> JSON(["Return JSON"])
    JSON --> CHECK_RESULTS{"Results found?"}
    
    CHECK_RESULTS -->|"No"| EMPTY(["*ü§ö No results found* _5_"])
    CHECK_RESULTS -->|"Yes"| FORMAT(["Format output _4_"])
    
    FORMAT --> RESPONSE(["Librarian response"])
    
    style TRIGGER fill:#FFFFCC,stroke:#F9A825,color:#000
    style METADATA fill:#FFFF99,stroke:#F9A825,color:#000
    style INFER fill:#FFFF99,stroke:#F9A825,color:#000
    style CLARIFY fill:#FFFF99,stroke:#F9A825,color:#000
    style BUILD fill:#FFFF99,stroke:#F9A825,color:#000
    style EXEC fill:#FFFFCC,stroke:#F9A825,color:#000
    style JSON fill:#FFFFCC,stroke:#F9A825,color:#000
    style FORMAT fill:#FFFF99,stroke:#F9A825,color:#000
    style RESPONSE fill:#FFFFCC,stroke:#F9A825,color:#000
    style CHECK fill:#FFFF99,stroke:#F9A825,color:#000
    style ERROR fill:#FFFF99,stroke:#F9A825,color:#000
    style CHECK_SYSTEM fill:#FFFF99,stroke:#F9A825,color:#000
    style BROKEN fill:#FFFF99,stroke:#F9A825,color:#000
    style CHECK_RESULTS fill:#FFFF99,stroke:#F9A825,color:#000
    style EMPTY fill:#FFFF99,stroke:#F9A825,color:#000
```

---

1. **Load Metadata (needs discussion)**

**Current behavior:**
- Reads `.librarian-index.json` (global metadata)
- Reads multiple `.topic-index.json` files (per-topic embeddings)

**Question:** Should metadata loading be:
- **Explicit:** Skill tells research.py which files to load
- **Implicit:** research.py auto-discovers based on query
- **Hybrid:** Skill pre-filters, research.py refines

---

2. **Scope Inference (needs discussion)**

**Question:** Can system infer scope from context?

**Scope definition:**
- **Currently:** Topic OR Book
- **Future:** Author, tags, date range

**Confidence threshold:**
- **Currently:** Unknown (not implemented)
- **Recommendation:** Start at **75%** (balance between interruptions vs errors)
  - Above 75% ‚Üí proceed with inference
  - Below 75% ‚Üí ask clarification
- **Logic:** Better to ask once than return wrong results

**Examples:**
- "pesquisa servitors" + previous conversation about chaos magick ‚Üí infer `--topics chaos-magick` (high confidence)
- "pesquisa economia" + no context ‚Üí ask "qual t√≥pico? finance? politics?" (low confidence)

---

5. **ü§ö HARD STOP Function**

**Purpose:** Protect librarian from futile execution. Honesty > helpfulness.

**What it means:**
- **AI stops immediately** - No attempt to answer from general knowledge
- **User sees exact message** (italics = verbatim user copy)
- **System state preserved** - No partial execution, no side effects

**When triggered:**
- *"ü§ö No metadata found: Run librarian index"* - Metadata missing
- *"ü§ö Say it again?"* - Scope unclear (low confidence)
- *"ü§ö System is broken"* - Python/library/research.py failure
- *"ü§ö No results found"* - Query returned empty (metadata ‚úÖ, scope ‚úÖ, system ‚úÖ, but nothing matches)

**Why centralized:**
- Refine ONCE, all nodes benefit
- Consistent user experience
- Clear protocol boundary (librarian servitor is bounded)

**VISION.md principle:** "N√£o achei" (honest) > invention (dishonest when user asked librarian specifically)

**Future:** See [v1.6.0 - Granular Error Handling](https://github.com/nonlinear/librarian/blob/main/backstage/ROADMAP.md#v160) for detailed error types (Python missing, timeout, disk full, etc.)

---

3. **Build Command**

**Question:** How to execute research.py?

**Syntax (from SKILL.md + research.py --help):**
```bash
cd ~/Documents/librarian && \
python3 engine/scripts/research.py "QUERY" --topic TOPIC_ID
# OR
python3 engine/scripts/research.py "QUERY" --book "filename.pdf"
```

**Parameters:**
- `--topic TOPIC_ID` - Topic name with underscores (e.g. `chaos-magick`)
- `--book "filename.pdf"` - Exact book filename
- `--top-k N` - Number of results (default: 5)
- `--context-window N` - Surrounding chunks (default: 1)

**Decision:** Where intelligence lives = TBD after diagram complete.

---

4. **Format Output**

**Current format (from research.prompt.md):**

```
According to DeLanda 1Ô∏è‚É£, gradients drive morphogenesis. This connects to Deleuze's concept 2Ô∏è‚É£.

---

**Topic:** anthropocene/theory

---

1Ô∏è‚É£ [Molecular Red.epub](../personal%20library/books/anthropocene/Molecular%20Red.epub)

    gradients drive morphogenesis matter

2Ô∏è‚É£ [A Thousand Plateaus.epub](../personal%20library/books/anthropocene/A%20Thousand%20Plateaus.epub)

    intensive differences create forms
```

**Structure:**
- Synthesized answer with emoji citations (1Ô∏è‚É£ 2Ô∏è‚É£ 3Ô∏è‚É£)
- `---` separator
- `**Topic:** {folder_path}` (not topic ID)
- `---` separator
- Citation list: emoji + `[filename](relative_path)` + indented 4-word snippet

**Future (v1.4.0 Source Precision):**
- Kavita deep-links (paragraph/page precision)
- Context snippets (¬±N chunks around match)

---

## üìã Tasks

### CLARIFY loop - Follow-up as further trigger

**Question:** When user clarifies scope after "Can you be clearer?", does system:
- A) Append to original trigger (smarter, less repetition)
- B) Treat as new trigger + context (simpler, current approach)

**Current decision:** B (new trigger + context). Test A in future.

**Why test:** If system can intelligently append context, reduces user friction.

**Epic:** Future enhancement (not blocking v0.15.0)

---

## üéØ Objective

**Document what we want from librarian based on what we have.**

Adapt:
- **Prompt** (SKILL.md)
- **Shell wrapper** (.sh)
- **Python script** (.py)

---

## ‚úÖ Success Metric

**Skill = Deterministic protocol**

- Trigger ‚Üí follows ENTIRE protocol
- AI helps with:
  - Interpretation (from books)
  - Output (formatting, citations)
- Deterministic (same query = same behavior)

---

## Current State (Before)

**SKILL.md is overloaded:**
- Protocol logic mixed with usage instructions
- Hard to separate "how Claw uses it" from "how it works internally"
- Maintenance burden (update both places when things change)

---

## Goal (After)

Move intelligence to project, keep skill minimal.

---

## üé® Arch: Diagram Color System

**Visual language for diagram evolution:**

### Color Meanings

**Grey (`#E0E0E0`):** Building diagram
- Node exists but not yet discussed
- Structure only, no decisions made

**Pink (`#FFB6C1`, black text):** Needs discussion
- All nodes with emoji numbers (1Ô∏è‚É£, 2Ô∏è‚É£, 3Ô∏è‚É£)
- Questions to answer before proceeding
- Marks decision points

**Yellow (`#FFEB3B`, black text):** Approved
- Discussed and decided
- Ready for implementation
- Cleared for execution

**Blue (`#2196F3`, white text):** Executed
- Code matches diagram
- Map = territory
- Documentation of reality

### State Transitions

```
Grey ‚Üí Pink: Add notes/questions (needs discussion)
Grey ‚Üí Yellow: No questions, approved as-is
Pink ‚Üí Yellow: Questions answered, approved
Yellow ‚Üí Blue: Code implemented

All Yellow = Ready to execute (I can run without Nicholas)
All Blue = Complete (diagram = documentation)
```

### Philosophy

**Important:** Ask ALL questions (technical + architecture) so Nicholas can get out of the way and I run safely without input.

**Goal:** Maximum parity between map (diagram) and territory (code).

---

**Status:** Grey flow started. Pink nodes = open questions.

---

## üîÑ Meta: Main Project + Side Project Pattern

**Observation:** We're using librarian (main project) to refine arch skill (side project).

**Pattern:**
- **Main:** Active work (librarian epic v0.15.0)
- **Side:** Meta-learning (arch skill protocol)
- **Method:** Extract learnings from main ‚Üí document in side

**Future need:** System to track:
- Which project is "main" (active epic)
- Which project is "side" (meta-learning from main's structure)
- Cross-pollination (learnings flow both ways)

**Example today:**
- Main: `~/Documents/librarian/` (epic v0.15.0 - skill protocol)
- Side: `~/.openclaw/skills/arch/` (future skill, learning from this session)
- Artifact: `arch-session-2026-02-08.md` (extracted learnings)

**Why important:**
- Prevents meta-work from hijacking main work
- Documents cross-project learnings
- Future skill can reference "how we built it"

**Task created:** Add to librarian ROADMAP or global backstage POLICY

---

## üéØ Why This Works (Nicholas's Pride)

**Sandbox = safe experimentation:**
- Epics isolated (branch)
- Diagrams versioned (epic-notes/)
- Nodes explicit (mermaid)

**Planning vs Execution separation:**
- **Planning (arch:):** I can opine freely, suggest, debate
- **Execution (post-diagram):** I execute without errors, everything agreed

**First epic = hard (create from scratch):**
- v0.15.0 = 29 commits, 4 hours, diagram completo

**Second epic = easy (alter existing):**
- v0.16.0 = "arch: add reranking node" ‚Üí 1 commit
- Diagram = living document, cada epic refina

**Key insight:**
- **Todos epics mudam estrutura** ‚Üí todos precisam arch
- **Epic notes tem diagrama** ‚Üí eu SEI estado atual
- **"arch: muda X"** ‚Üí eu SEI exatamente O QUE mudar, O QUE manter
- **Diff visual** ‚Üí screenshots mostram APENAS delta

**Low metabolic cost:** Alterar > recriar

**Nicholas:** "Acho OTIMO e to muito orgulhoso disso." ‚ú®

---

## üî¥ OPEN QUESTIONS (Must Resolve Before Execution)

### Q1: Load Metadata - Who's Responsible?
**Node:** `METADATA (Load metadata _1_)` - üî¥ RED (needs decision)

**Question:** Who loads `.librarian-index.json` + `.topic-index.json`?
- **Option A:** AI instructs (SKILL.md logic) ‚Üí wrapper validates
- **Option B:** Wrapper loads ‚Üí AI uses
- **Option C:** Python script auto-discovers ‚Üí wrapper/AI just execute

**Best practice alignment:** "Trust CLI to fail loudly" (official skills)

**Proposal:** Python script loads (research.py auto-discovers), wrapper validates exit code

---

### Q2: Infer Scope - AI or Script?
**Node:** `INFER (Infer scope? _2_)` - üî¥ RED (needs decision)

**Question:** Who infers topic from user query?
- **Option A:** AI infers (context-aware) ‚Üí wrapper validates topic exists
- **Option B:** Script infers (keyword matching) ‚Üí AI presents
- **Option C:** Hybrid (AI suggests, script confirms)

**Best practice alignment:** No official skill does scope inference (unique to us)

**Proposal:** AI infers from context (SKILL.md examples), wrapper validates topic folder exists

**Confidence threshold:** 75% (below = ask clarification)

---

### Q3: Build Command - Who Constructs CLI Args?
**Node:** `BUILD (Build command _3_)` - üî¥ RED (needs decision)

**Question:** Who builds `research.py "query" --topics X,Y`?
- **Option A:** AI builds from SKILL.md syntax ‚Üí wrapper executes
- **Option B:** Wrapper templates ‚Üí AI fills variables
- **Option C:** Script accepts natural language ‚Üí parses internally

**Best practice alignment:** "SKILL.md documents wrapper usage" (official pattern)

**Proposal:** AI builds command from SKILL.md examples, wrapper executes as-is

---

### Q4: Format Output - Wrapper or AI?
**Node:** `FORMAT (Format output _4_)` - üî¥ RED (needs decision)

**Question:** Who formats JSON ‚Üí Markdown citations (1Ô∏è‚É£ 2Ô∏è‚É£ 3Ô∏è‚É£)?
- **Option A:** Wrapper formats (consistent) ‚Üí AI presents
- **Option B:** AI formats (context-aware) ‚Üí wrapper validates
- **Option C:** Script outputs markdown ‚Üí wrapper/AI pass-through

**Best practice alignment:** "AI helps with formatting, citations" (official pattern)

**Proposal:** Wrapper formats (numbered citations), AI synthesizes answer + presents

---

## üìã EPIC SCOPE QUESTIONS (General, Not Node-Specific)

### Metadata Check - System Requirements
**Question:** Should we validate system before execution?
- Python version check
- Dependency check (sentence-transformers, torch, faiss)
- Disk space check

**Best practice:** "Metadata frontmatter declares requirements" (all official skills)

**Proposal:** Add frontmatter (Phase 3), validate at skill load time (not per-query)

---

### Frontmatter - What to Include?
**Question:** Which metadata fields?
- `emoji` üìö (visual identity)
- `requires.bins` ["python3", "jq"]
- `requires.python` ["sentence-transformers", "torch", "faiss-cpu"]
- `install` (pip install instructions)
- `os` ["darwin", "linux"]

**Proposal:** Add all above (standard pattern from official skills)

---

### Pre-Trigger Flow - Other Users
**Question:** How do other users configure triggers?
- Document in SKILL.md ("When to use" section)?
- Keep in AGENTS.md (user-editable)?
- Both (SKILL.md = examples, AGENTS.md = customization)?

**Best practice:** Some skills list triggers in SKILL.md (summarize.sh), some don't

**Proposal:** SKILL.md lists common triggers, AGENTS.md allows customization

---

### Triggers as Frontmatter?
**Question:** Should triggers be in YAML frontmatter?
```yaml
triggers:
  - "pesquisa {query} nos livros"
  - "search books for {topic}"
```

**Best practice:** No official skill does this (triggers in prose, not YAML)

**Proposal:** Keep triggers as prose in SKILL.md (easier for users to understand)

---

### Suggestion as Frontmatter?
**Question:** Should AI auto-suggest librarian based on patterns?
```yaml
auto_suggest:
  - pattern: "what do books say"
  - pattern: "research {topic}"
```

**Best practice:** No official skill does this

**Proposal:** DEFER to future epic (stabilize current behavior first)

---

### Expand SKILL.md Examples
**Question:** What examples to add?
- Multi-topic search
- Book-specific search
- Common queries (from usage.jsonl history)

**Best practice:** "Dense with examples (200+ lines, every feature)" (official pattern)

**Proposal:** Check `usage.jsonl` for real queries, document top 10 patterns

---

## üéØ Decision Rule

**Red nodes BLOCK execution.** We don't move until:
1. All red nodes ‚Üí yellow (approved)
2. All epic scope questions ‚Üí answered
3. Diagram = contract (I can execute unsupervised)

**Next step:** Nicholas reviews questions ‚Üí makes decisions ‚Üí nodes turn yellow ‚Üí we execute

---
