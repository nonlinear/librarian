**v0.15.0 - Skill as Protocol**

```mermaid
flowchart TB
    TRIGGER(["Trigger + context"])
    TRIGGER --> METADATA(["Load metadata (1)"])
    METADATA --> CHECK{"Metadata exists?"}
    
    CHECK -->|"No"| ERROR(["*ü§ö No metadata found:<br>Run librarian index* (7)"])
    CHECK -->|"Yes"| INFER{"Infer scope? (2)"}
    
    INFER -->|"confidence<br>lower than 75%"| CLARIFY(["*ü§ö Say it again?* (7)"])
    INFER -->|"confidence<br>higher than 75%"| BUILD(["Build command (3)"])
    
    BUILD --> CHECK_SYSTEM{"System working?"}
    
    CHECK_SYSTEM -->|"No"| BROKEN(["*ü§ö System is broken* (7)"])
    CHECK_SYSTEM -->|"Yes"| EXEC(["Run python script with flags"])
    
    EXEC --> JSON(["Return JSON"])
    JSON --> CHECK_RESULTS{"Results found?"}
    
    CHECK_RESULTS -->|"No"| EMPTY(["*ü§ö No results found* (7)"])
    CHECK_RESULTS -->|"Yes"| FORMAT(["Format output (5)"])
    
    FORMAT --> RESPONSE(["Librarian response"])
    
    style TRIGGER fill:#FFFFCC,stroke:#F9A825,color:#000
    style METADATA fill:#FFFF99,stroke:#F9A825,color:#000
    style INFER fill:#FFFF99,stroke:#F9A825,color:#000
    style CLARIFY fill:#FFFF99,stroke:#F9A825,color:#000
    style BUILD fill:#FFFF99,stroke:#F9A825,color:#000
    style EXEC fill:#FFFFCC,stroke:#F9A825,color:#000
    style JSON fill:#FFFFCC,stroke:#F9A825,color:#000
    style FORMAT fill:#FFFF99,stroke:#F9A825,color:#000
    style RESPONSE fill:#FFFFCC,stroke:#F9A825,color:#000
    style CHECK fill:#FFFF99,stroke:#F9A825,color:#000
    style ERROR fill:#FFFF99,stroke:#F9A825,color:#000
    style CHECK_SYSTEM fill:#FFFF99,stroke:#F9A825,color:#000
    style BROKEN fill:#FFFF99,stroke:#F9A825,color:#000
    style CHECK_RESULTS fill:#FFFF99,stroke:#F9A825,color:#000
    style EMPTY fill:#FFFF99,stroke:#F9A825,color:#000
```

---

1. **Load Metadata (needs discussion)**

**Current behavior:**
- Reads `.librarian-index.json` (global metadata)
- Reads multiple `.topic-index.json` files (per-topic embeddings)

**Question:** Should metadata loading be:
- **Explicit:** Skill tells research.py which files to load
- **Implicit:** research.py auto-discovers based on query
- **Hybrid:** Skill pre-filters, research.py refines

---

2. **Scope Inference (needs discussion)**

**Question:** Can system infer scope from context?

**Scope definition:**
- **Currently:** Topic OR Book
- **Future:** Author, tags, date range

**Confidence threshold:**
- **Currently:** Unknown (not implemented)
- **Recommendation:** Start at **75%** (balance between interruptions vs errors)
  - Above 75% ‚Üí proceed with inference
  - Below 75% ‚Üí ask clarification
- **Logic:** Better to ask once than return wrong results

**Examples:**
- "pesquisa servitors" + previous conversation about chaos magick ‚Üí infer `--topics chaos-magick` (high confidence)
- "pesquisa economia" + no context ‚Üí ask "qual t√≥pico? finance? politics?" (low confidence)

---

5. **ü§ö HARD STOP Function**

**Purpose:** Protect librarian from futile execution. Honesty > helpfulness.

**What it means:**
- **AI stops immediately** - No attempt to answer from general knowledge
- **User sees exact message** (italics = verbatim user copy)
- **System state preserved** - No partial execution, no side effects

**When triggered:**
- *"ü§ö No metadata found: Run librarian index"* - Metadata missing
- *"ü§ö Say it again?"* - Scope unclear (low confidence)
- *"ü§ö System is broken"* - Python/library/research.py failure
- *"ü§ö No results found"* - Query returned empty (metadata ‚úÖ, scope ‚úÖ, system ‚úÖ, but nothing matches)

**Why centralized:**
- Refine ONCE, all nodes benefit
- Consistent user experience
- Clear protocol boundary (librarian servitor is bounded)

**VISION.md principle:** "N√£o achei" (honest) > invention (dishonest when user asked librarian specifically)

**Future:** See [v1.6.0 - Granular Error Handling](https://github.com/nonlinear/librarian/blob/main/backstage/ROADMAP.md#v160) for detailed error types (Python missing, timeout, disk full, etc.)

---

3. **Build Command**

**Question:** How to execute research.py?

**Syntax (from SKILL.md + research.py --help):**
```bash
cd ~/Documents/librarian && \
python3 engine/scripts/research.py "QUERY" --topic TOPIC_ID
# OR
python3 engine/scripts/research.py "QUERY" --book "filename.pdf"
```

**Parameters:**
- `--topic TOPIC_ID` - Topic name with underscores (e.g. `chaos-magick`)
- `--book "filename.pdf"` - Exact book filename
- `--top-k N` - Number of results (default: 5)
- `--context-window N` - Surrounding chunks (default: 1)

**Decision:** Where intelligence lives = TBD after diagram complete.

---

4. **Format Output**

**Current format (from research.prompt.md):**

```
According to DeLanda 1Ô∏è‚É£, gradients drive morphogenesis. This connects to Deleuze's concept 2Ô∏è‚É£.

---

**Topic:** anthropocene/theory

---

1Ô∏è‚É£ [Molecular Red.epub](../personal%20library/books/anthropocene/Molecular%20Red.epub)

    gradients drive morphogenesis matter

2Ô∏è‚É£ [A Thousand Plateaus.epub](../personal%20library/books/anthropocene/A%20Thousand%20Plateaus.epub)

    intensive differences create forms
```

**Structure:**
- Synthesized answer with emoji citations (1Ô∏è‚É£ 2Ô∏è‚É£ 3Ô∏è‚É£)
- `---` separator
- `**Topic:** {folder_path}` (not topic ID)
- `---` separator
- Citation list: emoji + `[filename](relative_path)` + indented 4-word snippet

**Future (v1.4.0 Source Precision):**
- Kavita deep-links (paragraph/page precision)
- Context snippets (¬±N chunks around match)

---

## üìã Tasks

### CLARIFY loop - Follow-up as further trigger

**Question:** When user clarifies scope after "Can you be clearer?", does system:
- A) Append to original trigger (smarter, less repetition)
- B) Treat as new trigger + context (simpler, current approach)

**Current decision:** B (new trigger + context). Test A in future.

**Why test:** If system can intelligently append context, reduces user friction.

**Epic:** Future enhancement (not blocking v0.15.0)

---

## üéØ Objective

**Document what we want from librarian based on what we have.**

Adapt:
- **Prompt** (SKILL.md)
- **Shell wrapper** (.sh)
- **Python script** (.py)

---

## ‚úÖ Success Metric

**Skill = Deterministic protocol**

- Trigger ‚Üí follows ENTIRE protocol
- AI helps with:
  - Interpretation (from books)
  - Output (formatting, citations)
- Deterministic (same query = same behavior)

---

## Current State (Before)

**SKILL.md is overloaded:**
- Protocol logic mixed with usage instructions
- Hard to separate "how Claw uses it" from "how it works internally"
- Maintenance burden (update both places when things change)

---

## Goal (After)

Move intelligence to project, keep skill minimal.

---

## üé® Arch: Diagram Color System

**Visual language for diagram evolution:**

### Color Meanings

**Grey (`#E0E0E0`):** Building diagram
- Node exists but not yet discussed
- Structure only, no decisions made

**Pink (`#FFB6C1`, black text):** Needs discussion
- All nodes with emoji numbers (1Ô∏è‚É£, 2Ô∏è‚É£, 3Ô∏è‚É£)
- Questions to answer before proceeding
- Marks decision points

**Yellow (`#FFEB3B`, black text):** Approved
- Discussed and decided
- Ready for implementation
- Cleared for execution

**Blue (`#2196F3`, white text):** Executed
- Code matches diagram
- Map = territory
- Documentation of reality

### State Transitions

```
Grey ‚Üí Pink: Add notes/questions (needs discussion)
Grey ‚Üí Yellow: No questions, approved as-is
Pink ‚Üí Yellow: Questions answered, approved
Yellow ‚Üí Blue: Code implemented

All Yellow = Ready to execute (I can run without Nicholas)
All Blue = Complete (diagram = documentation)
```

### Philosophy

**Important:** Ask ALL questions (technical + architecture) so Nicholas can get out of the way and I run safely without input.

**Goal:** Maximum parity between map (diagram) and territory (code).

---

**Status:** Grey flow started. Pink nodes = open questions.
